{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>White Noise</td>\n",
       "      <td>https://en.wikipedia.org/wiki/White_Noise_(200...</td>\n",
       "      <td>\\nJonathan Rivers is an architect and lives wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coach Carter</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coach_Carter</td>\n",
       "      <td>\\nKen Carter lives in Richmond, California. He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Elektra</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Elektra_(2005_film)</td>\n",
       "      <td>\\nAfter being killed in Daredevil, Elektra Nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Racing Stripes</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Racing_Stripes</td>\n",
       "      <td>\\nDuring a thunderstorm, a traveling circus, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tom and Jerry: Blast Off to Mars</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tom_and_Jerry:_B...</td>\n",
       "      <td>\\nTom (voiced by Bill Kopp) chases Jerry as us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             title  \\\n",
       "0           0                       White Noise   \n",
       "1           1                      Coach Carter   \n",
       "2           2                           Elektra   \n",
       "3           3                    Racing Stripes   \n",
       "4           4  Tom and Jerry: Blast Off to Mars   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://en.wikipedia.org/wiki/White_Noise_(200...   \n",
       "1         https://en.wikipedia.org/wiki/Coach_Carter   \n",
       "2  https://en.wikipedia.org/wiki/Elektra_(2005_film)   \n",
       "3       https://en.wikipedia.org/wiki/Racing_Stripes   \n",
       "4  https://en.wikipedia.org/wiki/Tom_and_Jerry:_B...   \n",
       "\n",
       "                                                plot  \n",
       "0  \\nJonathan Rivers is an architect and lives wi...  \n",
       "1  \\nKen Carter lives in Richmond, California. He...  \n",
       "2  \\nAfter being killed in Daredevil, Elektra Nat...  \n",
       "3  \\nDuring a thunderstorm, a traveling circus, C...  \n",
       "4  \\nTom (voiced by Bill Kopp) chases Jerry as us...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_plots_file = 'movie_plots.csv'\n",
    "\n",
    "df = pd.read_csv(movie_plots_file, encoding='utf-8')\n",
    "df.drop_duplicates(subset='url', inplace=True, keep=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_plot = df[df['title'].str.match('Interstellar')].iloc[0]['plot']\n",
    "movie_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def get_noun_phrases(text):\n",
    "\n",
    "    candidates = []\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for np in doc.noun_chunks:\n",
    "        phrase = np.text.strip()\n",
    "        if phrase not in candidates:\n",
    "            candidates.append(phrase)\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "print (get_noun_phrases(movie_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "np_movie = get_noun_phrases(movie_plot)\n",
    "print(len(np_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "def get_doc_and_candidate_embeddings(model, doc, candidates):\n",
    "    doc_embedding = model.encode([doc])\n",
    "    candidate_embedding = model.encode(candidates)\n",
    "    return doc_embedding, candidate_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeds, keyphrase_embeds = get_doc_and_candidate_embeddings(model, movie_plot, np_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrase_doc_similarity = cosine_similarity(keyphrase_embeds, doc_embeds).flatten()\n",
    "keyphrase_doc_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_idx = np.argsort(keyphrase_doc_similarity)[::-1]\n",
    "\n",
    "print(keyphrase_doc_similarity[keywords_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_keywords = [np_movie[i] for i in keywords_idx]\n",
    "print(sorted_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import itertools\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://maartengr.github.io/KeyBERT/api/mmr.html#keybert._model.KeyBERT.extract_keywords\n",
    "def mmr(\n",
    "    doc_embedding: np.ndarray,\n",
    "    word_embeddings: np.ndarray,\n",
    "    words: List[str],\n",
    "    top_n: int = 5,\n",
    "    diversity: float = 0.8,\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"Calculate Maximal Marginal Relevance (MMR)\n",
    "    between candidate keywords and the document.\n",
    "\n",
    "\n",
    "    MMR considers the similarity of keywords/keyphrases with the\n",
    "    document, along with the similarity of already selected\n",
    "    keywords and keyphrases. This results in a selection of keywords\n",
    "    that maximize their within diversity with respect to the document.\n",
    "\n",
    "    Arguments:\n",
    "        doc_embedding: The document embeddings\n",
    "        word_embeddings: The embeddings of the selected candidate keywords/phrases\n",
    "        words: The selected candidate keywords/keyphrases\n",
    "        top_n: The number of keywords/keyhprases to return\n",
    "        diversity: How diverse the select keywords/keyphrases are.\n",
    "                   Values between 0 and 1 with 0 being not diverse at all\n",
    "                   and 1 being most diverse.\n",
    "\n",
    "    Returns:\n",
    "         List[Tuple[str, float]]: The selected keywords/keyphrases with their distances\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract similarity within words, and between words and the document\n",
    "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n",
    "    word_similarity = cosine_similarity(word_embeddings)\n",
    "\n",
    "    # Initialize candidates and already choose best keyword/keyphras\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    for _ in range(min(top_n - 1, len(words) - 1)):\n",
    "        # Extract similarities within candidates and\n",
    "        # between candidates and selected keywords/phrases\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(\n",
    "            word_similarity[candidates_idx][:, keywords_idx], axis=1\n",
    "        )\n",
    "\n",
    "        # Calculate MMR\n",
    "        mmr = (\n",
    "            1 - diversity\n",
    "        ) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # Update keywords & candidates\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    # Extract and sort keywords in descending similarity\n",
    "    keywords = [\n",
    "        (words[idx], round(float(word_doc_similarity.reshape(1, -1)[0][idx]), 4))\n",
    "        for idx in keywords_idx\n",
    "    ]\n",
    "    keywords = sorted(keywords, key=itemgetter(1), reverse=True)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-NASA pilot Cooper', 0.5708), ('Murph scientific data', 0.2713), ('blight', 0.2173), ('Government-run schools', 0.2145), ('massive tidal waves', 0.0725)]\n"
     ]
    }
   ],
   "source": [
    "mmr_keywords = mmr(doc_embeds, keyphrase_embeds, np_movie, top_n=5, diversity=0.8)\n",
    "print(mmr_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_sum_distance(\n",
    "    doc_embedding: np.ndarray,\n",
    "    word_embeddings: np.ndarray,\n",
    "    words: List[str],\n",
    "    top_n: int,\n",
    "    nr_candidates: int,\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"Calculate Max Sum Distance for extraction of keywords\n",
    "    We take the 2 x top_n most similar words/phrases to the document.\n",
    "    Then, we take all top_n combinations from the 2 x top_n words and\n",
    "    extract the combination that are the least similar to each other\n",
    "    by cosine similarity.\n",
    "    This is O(n^2) and therefore not advised if you use a large `top_n`\n",
    "    Arguments:\n",
    "        doc_embedding: The document embeddings\n",
    "        word_embeddings: The embeddings of the selected candidate keywords/phrases\n",
    "        words: The selected candidate keywords/keyphrases\n",
    "        top_n: The number of keywords/keyhprases to return\n",
    "        nr_candidates: The number of candidates to consider\n",
    "    Returns:\n",
    "         List[Tuple[str, float]]: The selected keywords/keyphrases with their distances\n",
    "    \"\"\"\n",
    "    if nr_candidates < top_n:\n",
    "        raise Exception(\n",
    "            \"Make sure that the number of candidates exceeds the number \"\n",
    "            \"of keywords to return.\"\n",
    "        )\n",
    "    elif top_n > len(words):\n",
    "        return []\n",
    "\n",
    "    # Calculate distances and extract keywords\n",
    "    distances = cosine_similarity(doc_embedding, word_embeddings)\n",
    "    distances_words = cosine_similarity(word_embeddings, word_embeddings)\n",
    "\n",
    "    # Get 2*top_n words as candidates based on cosine similarity\n",
    "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
    "    words_vals = [words[index] for index in words_idx]\n",
    "    candidates = distances_words[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "    # Calculate the combination of words that are the least similar to each other\n",
    "    min_sim = 100_000\n",
    "    candidate = None\n",
    "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "        sim = sum(\n",
    "            [candidates[i][j] for i in combination for j in combination if i != j]\n",
    "        )\n",
    "        if sim < min_sim:\n",
    "            candidate = combination\n",
    "            min_sim = sim\n",
    "\n",
    "    return [\n",
    "        (words_vals[idx], round(float(distances[0][words_idx[idx]]), 4))\n",
    "        for idx in candidate\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Cooper', 0.368), ('the previous NASA explorer', 0.3908), ('NASA volunteers', 0.4211), ('a global famine', 0.4284), ('The famine', 0.463)]\n"
     ]
    }
   ],
   "source": [
    "maxsum_keywords = max_sum_distance(doc_embeds, keyphrase_embeds, np_movie, top_n=5, nr_candidates=10)\n",
    "print(maxsum_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Similar Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = df['plot'].tolist()\n",
    "batmanbegins_plot = df[df['title'].str.match('Batman Begins')].iloc[0]['plot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batmanbegins_embedd, all_plots_embeds = \\\n",
    "    get_doc_and_candidate_embeddings(model, batmanbegins_plot, all_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Batman Begins', 'The Dark Knight', 'The Lego Batman Movie', 'The Batman vs. Dracula', 'Batman: The Killing Joke', 'Birds of Prey', 'Joker', 'Killshot', 'All Eyez on Me', 'Setup']\n"
     ]
    }
   ],
   "source": [
    "plot_similarity = cosine_similarity(batmanbegins_embedd, all_plots_embeds).flatten()\n",
    "plots_idx = np.argsort(plot_similarity)[::-1]\n",
    "\n",
    "sorted_titles = [df.iloc[idx]['title'] for idx in plots_idx]\n",
    "\n",
    "print(sorted_titles[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "077154c964289b0082ac918d2b82cb60751fdd6fadff035c46d3a5af3149f689"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
